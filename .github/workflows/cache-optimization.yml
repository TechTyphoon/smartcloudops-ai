name: 🗂️ Cache Optimization & Cleanup

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      cache_action:
        description: 'Cache action to perform'
        required: true
        default: 'cleanup'
        type: choice
        options:
          - cleanup
          - analyze
          - rebuild
      days_to_keep:
        description: 'Days to keep cache entries'
        required: false
        default: '7'
        type: string

permissions:
  actions: write
  contents: read

jobs:
  cache-analysis:
    name: 🔍 Cache Analysis
    runs-on: ubuntu-latest
    if: inputs.cache_action == 'analyze' || inputs.cache_action == 'cleanup'
    
    steps:
    - name: 📥 Checkout
      uses: actions/checkout@v4
      
    - name: 🔍 Analyze cache usage
      uses: actions/github-script@v7
      with:
        script: |
          const { Octokit } = require('@octokit/rest');
          const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });
          
          try {
            // Get cache entries
            const { data: caches } = await octokit.rest.actions.getActionsCacheList({
              owner: context.repo.owner,
              repo: context.repo.repo,
              per_page: 100
            });
            
            console.log(`📊 Cache Analysis Results`);
            console.log(`Total cache entries: ${caches.total_count}`);
            
            let totalSize = 0;
            const cachesByKey = {};
            const cachesByRef = {};
            
            for (const cache of caches.actions_caches) {
              totalSize += cache.size_in_bytes;
              
              // Group by key
              if (!cachesByKey[cache.key]) {
                cachesByKey[cache.key] = [];
              }
              cachesByKey[cache.key].push(cache);
              
              // Group by ref
              if (!cachesByRef[cache.ref]) {
                cachesByRef[cache.ref] = [];
              }
              cachesByRef[cache.ref].push(cache);
            }
            
            console.log(`Total size: ${(totalSize / 1024 / 1024).toFixed(2)} MB`);
            console.log(`\n🔑 Cache keys (top 10):`);
            
            Object.entries(cachesByKey)
              .sort((a, b) => b[1].length - a[1].length)
              .slice(0, 10)
              .forEach(([key, entries]) => {
                const size = entries.reduce((sum, e) => sum + e.size_in_bytes, 0);
                console.log(`  ${key}: ${entries.length} entries, ${(size / 1024 / 1024).toFixed(2)} MB`);
              });
              
            console.log(`\n🌿 Branches with cache:`);
            Object.entries(cachesByRef)
              .sort((a, b) => b[1].length - a[1].length)
              .forEach(([ref, entries]) => {
                const size = entries.reduce((sum, e) => sum + e.size_in_bytes, 0);
                console.log(`  ${ref}: ${entries.length} entries, ${(size / 1024 / 1024).toFixed(2)} MB`);
              });
              
            // Find old caches
            const cutoffDate = new Date();
            cutoffDate.setDate(cutoffDate.getDate() - (parseInt('${{ inputs.days_to_keep || '7' }}') || 7));
            
            const oldCaches = caches.actions_caches.filter(cache => 
              new Date(cache.last_accessed_at) < cutoffDate
            );
            
            console.log(`\n🗑️ Old caches (older than ${cutoffDate.toDateString()}):`);
            console.log(`Count: ${oldCaches.length}`);
            
            if (oldCaches.length > 0) {
              const oldSize = oldCaches.reduce((sum, cache) => sum + cache.size_in_bytes, 0);
              console.log(`Size to be cleaned: ${(oldSize / 1024 / 1024).toFixed(2)} MB`);
              
              // Set output for cleanup job
              core.setOutput('old_cache_ids', oldCaches.map(c => c.id).join(','));
              core.setOutput('cleanup_needed', 'true');
            } else {
              core.setOutput('cleanup_needed', 'false');
            }
            
          } catch (error) {
            console.error('Error analyzing caches:', error);
            core.setFailed('Cache analysis failed');
          }
    
    outputs:
      old_cache_ids: ${{ steps.analyze.outputs.old_cache_ids }}
      cleanup_needed: ${{ steps.analyze.outputs.cleanup_needed }}

  cache-cleanup:
    name: 🗑️ Cache Cleanup
    runs-on: ubuntu-latest
    needs: cache-analysis
    if: needs.cache-analysis.outputs.cleanup_needed == 'true' || inputs.cache_action == 'cleanup'
    
    steps:
    - name: 🗑️ Clean old caches
      uses: actions/github-script@v7
      with:
        script: |
          const { Octokit } = require('@octokit/rest');
          const octokit = new Octokit({ auth: process.env.GITHUB_TOKEN });
          
          try {
            // Get all caches
            const { data: caches } = await octokit.rest.actions.getActionsCacheList({
              owner: context.repo.owner,
              repo: context.repo.repo,
              per_page: 100
            });
            
            const cutoffDate = new Date();
            cutoffDate.setDate(cutoffDate.getDate() - (parseInt('${{ inputs.days_to_keep || '7' }}') || 7));
            
            const oldCaches = caches.actions_caches.filter(cache => 
              new Date(cache.last_accessed_at) < cutoffDate
            );
            
            console.log(`🗑️ Cleaning ${oldCaches.length} old cache entries...`);
            
            let deletedCount = 0;
            let deletedSize = 0;
            
            for (const cache of oldCaches) {
              try {
                await octokit.rest.actions.deleteActionsCacheById({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  cache_id: cache.id
                });
                
                deletedCount++;
                deletedSize += cache.size_in_bytes;
                console.log(`  ✅ Deleted cache ${cache.key} (${(cache.size_in_bytes / 1024 / 1024).toFixed(2)} MB)`);
                
              } catch (error) {
                console.error(`  ❌ Failed to delete cache ${cache.key}:`, error.message);
              }
            }
            
            console.log(`\n📊 Cleanup Summary:`);
            console.log(`  Deleted entries: ${deletedCount}`);
            console.log(`  Space freed: ${(deletedSize / 1024 / 1024).toFixed(2)} MB`);
            
          } catch (error) {
            console.error('Error during cleanup:', error);
            core.setFailed('Cache cleanup failed');
          }

  cache-rebuild:
    name: 🔄 Cache Rebuild
    runs-on: ubuntu-latest
    if: inputs.cache_action == 'rebuild'
    
    strategy:
      matrix:
        cache-type: [dependencies, docker]
        
    steps:
    - name: 📥 Checkout
      uses: actions/checkout@v4
      
    - name: 🐍 Rebuild Python cache
      if: matrix.cache-type == 'dependencies'
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
        
    - name: 📦 Install Python dependencies
      if: matrix.cache-type == 'dependencies'
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: 🟢 Rebuild Node.js cache
      if: matrix.cache-type == 'dependencies' && hashFiles('frontend/package.json') != ''
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: 'frontend/package-lock.json'
        
    - name: 📦 Install Node.js dependencies
      if: matrix.cache-type == 'dependencies' && hashFiles('frontend/package.json') != ''
      run: |
        cd frontend
        npm ci
        
    - name: 🐳 Rebuild Docker cache
      if: matrix.cache-type == 'docker'
      uses: docker/setup-buildx-action@v3
      
    - name: 🏗️ Build Docker images for cache
      if: matrix.cache-type == 'docker'
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile.production
        platforms: linux/amd64
        push: false
        cache-from: type=gha,scope=production-linux/amd64
        cache-to: type=gha,mode=max,scope=production-linux/amd64
        
  cache-report:
    name: 📊 Cache Report
    runs-on: ubuntu-latest
    needs: [cache-analysis, cache-cleanup]
    if: always()
    
    steps:
    - name: 📊 Generate cache report
      run: |
        echo "# 🗂️ Cache Optimization Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Date**: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "**Action**: ${{ inputs.cache_action || 'scheduled cleanup' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.cache-analysis.result }}" == "success" ]]; then
          echo "✅ **Cache Analysis**: Completed successfully" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Cache Analysis**: Failed or skipped" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [[ "${{ needs.cache-cleanup.result }}" == "success" ]]; then
          echo "✅ **Cache Cleanup**: Completed successfully" >> $GITHUB_STEP_SUMMARY
        elif [[ "${{ needs.cache-cleanup.result }}" == "skipped" ]]; then
          echo "⏭️ **Cache Cleanup**: Skipped (no cleanup needed)" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Cache Cleanup**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## 💡 Recommendations" >> $GITHUB_STEP_SUMMARY
        echo "- Monitor cache usage weekly" >> $GITHUB_STEP_SUMMARY
        echo "- Keep cache retention between 3-14 days based on development velocity" >> $GITHUB_STEP_SUMMARY
        echo "- Consider cache key optimization for frequently changing dependencies" >> $GITHUB_STEP_SUMMARY
